"""
LunarLander-v3 DQN Algorithms - ì‹œê³„ì—´ ì‹œê°í™”
4ê°œ ì•Œê³ ë¦¬ì¦˜ì˜ í•™ìŠµ ê³¼ì •ì„ ë¹„êµí•˜ëŠ” ê·¸ë˜í”„ ìƒì„±
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from pathlib import Path

# í•œê¸€ í°íŠ¸ ì„¤ì • (macOS)
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# ì•Œê³ ë¦¬ì¦˜ ìƒ‰ìƒ ì •ì˜
COLORS = {
    'vanilla': '#FF6B6B',      # Red
    'double': '#4ECDC4',       # Cyan
    'dueling': '#FFD93D',      # Yellow
    'd3qn': '#6BCB77'          # Green
}

LABELS = {
    'vanilla': 'Vanilla DQN',
    'double': 'Double DQN',
    'dueling': 'Dueling DQN',
    'd3qn': 'D3QN'
}


def load_training_data(algorithm):
    """ì•Œê³ ë¦¬ì¦˜ë³„ í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
    data_file = Path(f'training_logs/{algorithm}_log.json')
    if data_file.exists():
        with open(data_file, 'r') as f:
            return json.load(f)
    return None


def plot_reward_comparison():
    """í‰ê·  ë³´ìƒ ë¹„êµ ê·¸ë˜í”„"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    for algo in ['vanilla', 'double', 'dueling', 'd3qn']:
        data = load_training_data(algo)
        if data is None:
            continue

        episodes = data['episodes']
        avg_rewards = data['avg_rewards']

        # ì´ë™ í‰ê·  ê³„ì‚° (50 ì—í”¼ì†Œë“œ)
        window = 50
        if len(avg_rewards) >= window:
            moving_avg = np.convolve(avg_rewards, np.ones(window)/window, mode='valid')
            moving_episodes = episodes[window-1:]
        else:
            moving_avg = avg_rewards
            moving_episodes = episodes

        # ì›ë³¸ ë°ì´í„° (íˆ¬ëª…)
        ax1.plot(episodes, avg_rewards, color=COLORS[algo], alpha=0.2, linewidth=0.5)
        # ì´ë™ í‰ê·  (ì§„í•˜ê²Œ)
        ax1.plot(moving_episodes, moving_avg, color=COLORS[algo],
                label=LABELS[algo], linewidth=2)

    ax1.set_xlabel('Episode', fontsize=12)
    ax1.set_ylabel('Average Reward (10 episodes)', fontsize=12)
    ax1.set_title('í•™ìŠµ ê³¡ì„  - í‰ê·  ë³´ìƒ ì¶”ì´', fontsize=14, fontweight='bold')
    ax1.legend(fontsize=10, loc='lower right')
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=200, color='red', linestyle='--', alpha=0.5, label='ëª©í‘œ (200+)')

    # ìµœê³  ë³´ìƒ ë¹„êµ
    for algo in ['vanilla', 'double', 'dueling', 'd3qn']:
        data = load_training_data(algo)
        if data is None:
            continue

        episodes = data['episodes']
        best_rewards = data['best_rewards']

        ax2.plot(episodes, best_rewards, color=COLORS[algo],
                label=LABELS[algo], linewidth=2)

    ax2.set_xlabel('Episode', fontsize=12)
    ax2.set_ylabel('Best Reward', fontsize=12)
    ax2.set_title('ìµœê³  ë³´ìƒ ì¶”ì´', fontsize=14, fontweight='bold')
    ax2.legend(fontsize=10, loc='lower right')
    ax2.grid(True, alpha=0.3)
    ax2.axhline(y=300, color='red', linestyle='--', alpha=0.5, label='ëª©í‘œ (300+)')

    plt.tight_layout()
    plt.savefig('visualizations/reward_comparison.png', dpi=300, bbox_inches='tight')
    print("âœ… ì €ì¥ë¨: visualizations/reward_comparison.png")
    plt.close()


def plot_test_performance():
    """í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ë¹„êµ (ë§¤ 100 ì—í”¼ì†Œë“œ)"""
    fig, ax = plt.subplots(figsize=(14, 7))

    test_episodes = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]

    for algo in ['vanilla', 'double', 'dueling', 'd3qn']:
        data = load_training_data(algo)
        if data is None:
            continue

        test_rewards = data.get('test_rewards', [])
        if len(test_rewards) > 0:
            ax.plot(test_episodes[:len(test_rewards)], test_rewards,
                   color=COLORS[algo], marker='o', markersize=8,
                   label=LABELS[algo], linewidth=2)

    ax.set_xlabel('Episode', fontsize=12)
    ax.set_ylabel('Test Reward', fontsize=12)
    ax.set_title('í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ë¹„êµ (ë§¤ 100 ì—í”¼ì†Œë“œ)', fontsize=14, fontweight='bold')
    ax.legend(fontsize=11, loc='lower right')
    ax.grid(True, alpha=0.3)
    ax.axhline(y=200, color='green', linestyle='--', alpha=0.5, linewidth=2, label='ì„±ê³µ ê¸°ì¤€ (200)')
    ax.axhline(y=0, color='red', linestyle='--', alpha=0.3, linewidth=1)

    plt.tight_layout()
    plt.savefig('visualizations/test_performance.png', dpi=300, bbox_inches='tight')
    print("âœ… ì €ì¥ë¨: visualizations/test_performance.png")
    plt.close()


def plot_loss_comparison():
    """Loss ì¶”ì´ ë¹„êµ"""
    fig, ax = plt.subplots(figsize=(14, 7))

    for algo in ['vanilla', 'double', 'dueling', 'd3qn']:
        data = load_training_data(algo)
        if data is None:
            continue

        episodes = data['episodes']
        losses = data.get('losses', [])

        if len(losses) > 0:
            # ì´ë™ í‰ê· ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ
            window = 20
            if len(losses) >= window:
                moving_avg = np.convolve(losses, np.ones(window)/window, mode='valid')
                moving_episodes = episodes[window-1:]
            else:
                moving_avg = losses
                moving_episodes = episodes

            ax.plot(episodes, losses, color=COLORS[algo], alpha=0.2, linewidth=0.5)
            ax.plot(moving_episodes, moving_avg, color=COLORS[algo],
                   label=LABELS[algo], linewidth=2)

    ax.set_xlabel('Episode', fontsize=12)
    ax.set_ylabel('Loss', fontsize=12)
    ax.set_title('Loss ì¶”ì´ ë¹„êµ', fontsize=14, fontweight='bold')
    ax.legend(fontsize=11, loc='upper right')
    ax.grid(True, alpha=0.3)
    ax.set_ylim(bottom=0)

    plt.tight_layout()
    plt.savefig('visualizations/loss_comparison.png', dpi=300, bbox_inches='tight')
    print("âœ… ì €ì¥ë¨: visualizations/loss_comparison.png")
    plt.close()


def plot_epsilon_comparison():
    """Epsilon ê°ì†Œ ì¶”ì´"""
    fig, ax = plt.subplots(figsize=(14, 7))

    for algo in ['vanilla', 'double', 'dueling', 'd3qn']:
        data = load_training_data(algo)
        if data is None:
            continue

        episodes = data['episodes']
        epsilons = data.get('epsilons', [])

        if len(epsilons) > 0:
            ax.plot(episodes, epsilons, color=COLORS[algo],
                   label=LABELS[algo], linewidth=2)

    ax.set_xlabel('Episode', fontsize=12)
    ax.set_ylabel('Epsilon (Exploration Rate)', fontsize=12)
    ax.set_title('Epsilon ê°ì†Œ ì¶”ì´', fontsize=14, fontweight='bold')
    ax.legend(fontsize=11, loc='upper right')
    ax.grid(True, alpha=0.3)
    ax.set_ylim(0, 1.05)

    plt.tight_layout()
    plt.savefig('visualizations/epsilon_comparison.png', dpi=300, bbox_inches='tight')
    print("âœ… ì €ì¥ë¨: visualizations/epsilon_comparison.png")
    plt.close()


def plot_final_comparison():
    """ìµœì¢… ì„±ëŠ¥ ë¹„êµ (ë§‰ëŒ€ ê·¸ë˜í”„)"""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

    algorithms = []
    best_rewards = []
    final_avg_rewards = []
    final_test_rewards = []

    for algo in ['vanilla', 'double', 'dueling', 'd3qn']:
        data = load_training_data(algo)
        if data is None:
            continue

        algorithms.append(LABELS[algo])
        best_rewards.append(max(data['best_rewards']))
        final_avg_rewards.append(data['avg_rewards'][-1] if data['avg_rewards'] else 0)

        # ìµœì¢… 3íšŒ í…ŒìŠ¤íŠ¸ í‰ê· 
        final_tests = data.get('final_test_rewards', [])
        final_test_rewards.append(np.mean(final_tests) if final_tests else 0)

    x_pos = np.arange(len(algorithms))
    colors = [COLORS[algo] for algo in ['vanilla', 'double', 'dueling', 'd3qn'][:len(algorithms)]]

    # ìµœê³  ë³´ìƒ
    bars1 = ax1.bar(x_pos, best_rewards, color=colors, alpha=0.8)
    ax1.set_ylabel('Best Reward', fontsize=11)
    ax1.set_title('ìµœê³  ë³´ìƒ ë¹„êµ', fontsize=13, fontweight='bold')
    ax1.set_xticks(x_pos)
    ax1.set_xticklabels(algorithms)
    ax1.grid(axis='y', alpha=0.3)
    for i, v in enumerate(best_rewards):
        ax1.text(i, v + 5, f'{v:.1f}', ha='center', va='bottom', fontweight='bold')

    # ìµœì¢… 10-í‰ê· 
    bars2 = ax2.bar(x_pos, final_avg_rewards, color=colors, alpha=0.8)
    ax2.set_ylabel('Final 10-Episode Average', fontsize=11)
    ax2.set_title('ìµœì¢… 10-ì—í”¼ì†Œë“œ í‰ê·  ë¹„êµ', fontsize=13, fontweight='bold')
    ax2.set_xticks(x_pos)
    ax2.set_xticklabels(algorithms)
    ax2.grid(axis='y', alpha=0.3)
    for i, v in enumerate(final_avg_rewards):
        ax2.text(i, v + 5, f'{v:.1f}', ha='center', va='bottom', fontweight='bold')

    # ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê· 
    bars3 = ax3.bar(x_pos, final_test_rewards, color=colors, alpha=0.8)
    ax3.set_ylabel('Final Test Average', fontsize=11)
    ax3.set_title('ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê·  (Best Model 3íšŒ)', fontsize=13, fontweight='bold')
    ax3.set_xticks(x_pos)
    ax3.set_xticklabels(algorithms)
    ax3.grid(axis='y', alpha=0.3)
    ax3.axhline(y=200, color='green', linestyle='--', alpha=0.5, linewidth=2)
    for i, v in enumerate(final_test_rewards):
        ax3.text(i, v + 5, f'{v:.1f}', ha='center', va='bottom', fontweight='bold')

    # ì¢…í•© ì ìˆ˜ (í‘œì¤€í™”)
    if len(algorithms) > 0:
        # ê° ì§€í‘œë¥¼ 0-100ìœ¼ë¡œ ì •ê·œí™”
        norm_best = [(x / max(best_rewards)) * 100 for x in best_rewards]
        norm_avg = [(x / max(final_avg_rewards)) * 100 if max(final_avg_rewards) > 0 else 0 for x in final_avg_rewards]
        norm_test = [(x / max(final_test_rewards)) * 100 if max(final_test_rewards) > 0 else 0 for x in final_test_rewards]

        total_scores = [(a + b + c) / 3 for a, b, c in zip(norm_best, norm_avg, norm_test)]

        bars4 = ax4.bar(x_pos, total_scores, color=colors, alpha=0.8)
        ax4.set_ylabel('ì¢…í•© ì ìˆ˜ (0-100)', fontsize=11)
        ax4.set_title('ì¢…í•© ì„±ëŠ¥ ë¹„êµ', fontsize=13, fontweight='bold')
        ax4.set_xticks(x_pos)
        ax4.set_xticklabels(algorithms)
        ax4.grid(axis='y', alpha=0.3)
        ax4.set_ylim(0, 105)
        for i, v in enumerate(total_scores):
            ax4.text(i, v + 2, f'{v:.1f}', ha='center', va='bottom', fontweight='bold')

    plt.tight_layout()
    plt.savefig('visualizations/final_comparison.png', dpi=300, bbox_inches='tight')
    print("âœ… ì €ì¥ë¨: visualizations/final_comparison.png")
    plt.close()


def plot_success_rate():
    """ì„±ê³µë¥  ë¶„ì„ (200+ ë³´ìƒ ë‹¬ì„± ë¹„ìœ¨)"""
    fig, ax = plt.subplots(figsize=(14, 7))

    for algo in ['vanilla', 'double', 'dueling', 'd3qn']:
        data = load_training_data(algo)
        if data is None:
            continue

        episodes = data['episodes']
        avg_rewards = data['avg_rewards']

        # 100 ì—í”¼ì†Œë“œ ë‹¨ìœ„ë¡œ ì„±ê³µë¥  ê³„ì‚°
        window = 100
        success_rates = []
        success_episodes = []

        for i in range(0, len(avg_rewards), window):
            end_idx = min(i + window, len(avg_rewards))
            window_rewards = avg_rewards[i:end_idx]
            success_rate = sum(1 for r in window_rewards if r >= 200) / len(window_rewards) * 100
            success_rates.append(success_rate)
            success_episodes.append(episodes[end_idx - 1])

        ax.plot(success_episodes, success_rates, color=COLORS[algo],
               marker='o', markersize=6, label=LABELS[algo], linewidth=2)

    ax.set_xlabel('Episode', fontsize=12)
    ax.set_ylabel('Success Rate (%)', fontsize=12)
    ax.set_title('ì„±ê³µë¥  ì¶”ì´ (200+ ë³´ìƒ ë‹¬ì„± ë¹„ìœ¨, 100 ì—í”¼ì†Œë“œ ë‹¨ìœ„)', fontsize=14, fontweight='bold')
    ax.legend(fontsize=11, loc='lower right')
    ax.grid(True, alpha=0.3)
    ax.set_ylim(0, 105)
    ax.axhline(y=80, color='green', linestyle='--', alpha=0.5, linewidth=2, label='ëª©í‘œ (80%)')

    plt.tight_layout()
    plt.savefig('visualizations/success_rate.png', dpi=300, bbox_inches='tight')
    print("âœ… ì €ì¥ë¨: visualizations/success_rate.png")
    plt.close()


def create_all_visualizations():
    """ëª¨ë“  ì‹œê°í™” ìƒì„±"""
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    Path('visualizations').mkdir(exist_ok=True)

    print("\n" + "="*60)
    print("ğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")
    print("="*60)

    try:
        plot_reward_comparison()
        plot_test_performance()
        plot_loss_comparison()
        plot_epsilon_comparison()
        plot_final_comparison()
        plot_success_rate()

        print("\n" + "="*60)
        print("âœ… ëª¨ë“  ì‹œê°í™” ì™„ë£Œ!")
        print("="*60)
        print("\nìƒì„±ëœ íŒŒì¼:")
        print("  - visualizations/reward_comparison.png")
        print("  - visualizations/test_performance.png")
        print("  - visualizations/loss_comparison.png")
        print("  - visualizations/epsilon_comparison.png")
        print("  - visualizations/final_comparison.png")
        print("  - visualizations/success_rate.png")
        print()

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    create_all_visualizations()
